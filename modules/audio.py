"""
Audio Module for Wall-E Companion Robot
Owner: Boymirzo

This module handles all audio input and output according to the API contract.
Implements speech recognition, text-to-speech, and AI integration.
"""

import logging
import time
import threading
from typing import Optional
import queue

# Audio processing imports (uncomment when dependencies are installed)
# import speech_recognition as sr
# import pyttsx3
# import pyaudio
# import wave

# AI/LLM imports (uncomment when dependencies are installed)
# import openai
# from transformers import pipeline

logger = logging.getLogger(__name__)

# Global variables
_audio_initialized = False
_recognizer = None
_microphone = None
_tts_engine = None
_ai_model = None
_speech_queue = queue.Queue()
_tts_thread = None

# Configuration
SPEECH_TIMEOUT = 5.0  # Seconds to wait for speech
SPEECH_PHRASE_TIMEOUT = 1.0  # Seconds of silence to end phrase
AI_MODEL_NAME = "gpt-3.5-turbo"  # OpenAI model or local model name

def setup() -> None:
    """
    Initializes audio hardware (microphone and speakers).
    Sets up speech recognition and text-to-speech engines.
    Must be called before any other audio functions.
    Raises RuntimeError if audio hardware initialization fails.
    """
    global _audio_initialized, _recognizer, _microphone, _tts_engine, _ai_model
    
    logger.info("Initializing audio system...")
    
    try:
        # TODO: Uncomment when running with actual audio hardware
        # # Initialize speech recognition
        # _recognizer = sr.Recognizer()
        # _microphone = sr.Microphone()
        
        # # Adjust for ambient noise
        # logger.info("Adjusting for ambient noise...")
        # with _microphone as source:
        #     _recognizer.adjust_for_ambient_noise(source, duration=2)
        
        # # Initialize text-to-speech
        # _tts_engine = pyttsx3.init()
        # _tts_engine.setProperty('rate', 150)  # Speaking rate
        # _tts_engine.setProperty('volume', 0.8)  # Volume level
        
        # # Set voice (optional - choose male/female voice)
        # voices = _tts_engine.getProperty('voices')
        # if voices:
        #     _tts_engine.setProperty('voice', voices[0].id)  # Use first available voice
        
        # # Initialize AI model
        # _init_ai_model()
        
        _audio_initialized = True
        logger.info("Audio system initialized successfully")
        
        # TEMPORARY: Simulation mode for development
        logger.warning("Running in SIMULATION mode - no actual audio processing")
        _audio_initialized = True
        
    except Exception as e:
        logger.error(f"Failed to initialize audio system: {e}")
        raise RuntimeError(f"Audio initialization failed: {e}")

def _init_ai_model() -> None:
    """Initialize the AI model for intelligent responses."""
    global _ai_model
    
    try:
        # Option 1: OpenAI API (requires API key)
        # openai.api_key = "your-api-key-here"  # Set your API key
        # logger.info("OpenAI API initialized")
        
        # Option 2: Local Hugging Face model (for offline operation)
        # _ai_model = pipeline("text-generation", model="microsoft/DialoGPT-medium")
        # logger.info("Local AI model loaded")
        
        # TEMPORARY: Simulation mode
        logger.info("AI model initialized (simulation mode)")
        
    except Exception as e:
        logger.warning(f"Could not initialize AI model: {e}")
        _ai_model = None

def listen_and_transcribe() -> str:
    """
    Listens for speech, transcribes it, and returns the recognized text as a string.
    Blocks until speech is detected and processed.
    
    Returns:
        str: Recognized text, or empty string if no speech recognized
    """
    if not _audio_initialized:
        logger.warning("Audio system not initialized")
        return ""
    
    try:
        # TODO: Uncomment when running with actual audio hardware
        # logger.debug("Listening for speech...")
        # 
        # with _microphone as source:
        #     # Listen for audio with timeout
        #     try:
        #         audio = _recognizer.listen(source, timeout=SPEECH_TIMEOUT, 
        #                                  phrase_time_limit=SPEECH_PHRASE_TIMEOUT)
        #     except sr.WaitTimeoutError:
        #         logger.debug("No speech detected within timeout")
        #         return ""
        # 
        # # Recognize speech using Google Speech Recognition
        # try:
        #     text = _recognizer.recognize_google(audio)
        #     logger.info(f"Speech recognized: '{text}'")
        #     return text.lower()  # Return lowercase for easier processing
        # except sr.UnknownValueError:
        #     logger.debug("Could not understand audio")
        #     return ""
        # except sr.RequestError as e:
        #     logger.error(f"Speech recognition service error: {e}")
        #     return ""
        
        # TEMPORARY: Simulation mode - return dummy commands occasionally
        import random
        time.sleep(1)  # Simulate listening time
        
        dummy_commands = [
            "", "", "", "",  # Most of the time, no command
            "hello wall-e",
            "follow me",
            "stop",
            "how are you",
            "what do you see"
        ]
        
        command = random.choice(dummy_commands)
        if command:
            logger.info(f"SIMULATION: Speech recognized: '{command}'")
        
        return command
        
    except Exception as e:
        logger.error(f"Error in speech recognition: {e}")
        return ""

def speak(text: str) -> None:
    """
    Takes a string of text and speaks it out loud using text-to-speech.
    Non-blocking: returns immediately while speech continues in background.
    
    Args:
        text: The message to be spoken
        
    Raises:
        ValueError: If text is empty or None
    """
    if not text or not text.strip():
        raise ValueError("Text cannot be empty or None")
    
    if not _audio_initialized:
        logger.warning("Audio system not initialized")
        return
    
    logger.info(f"Speaking: '{text}'")
    
    # Add to speech queue for background processing
    _speech_queue.put(text)
    
    # Start TTS thread if not already running
    _start_tts_thread()

def _start_tts_thread() -> None:
    """Start the text-to-speech thread if not already running."""
    global _tts_thread
    
    if _tts_thread is None or not _tts_thread.is_alive():
        _tts_thread = threading.Thread(target=_tts_worker, daemon=True)
        _tts_thread.start()

def _tts_worker() -> None:
    """Background worker for text-to-speech processing."""
    while True:
        try:
            # Get text from queue (blocks until available)
            text = _speech_queue.get(timeout=1.0)
            
            # TODO: Uncomment when running with actual TTS
            # _tts_engine.say(text)
            # _tts_engine.runAndWait()
            
            # TEMPORARY: Simulation mode
            logger.info(f"SIMULATION: Speaking '{text}' (duration: {len(text) * 0.1:.1f}s)")
            time.sleep(len(text) * 0.1)  # Simulate speaking time
            
            _speech_queue.task_done()
            
        except queue.Empty:
            # No more text to speak, thread can exit
            break
        except Exception as e:
            logger.error(f"Error in TTS worker: {e}")

def get_intelligent_response(prompt: str) -> str:
    """
    Sends a text prompt to the LLM and returns the AI's response.
    Handles API rate limiting and network errors gracefully.
    
    Args:
        prompt: User's question or statement to send to AI
        
    Returns:
        str: AI's response, or error message if LLM is unavailable
    """
    if not prompt or not prompt.strip():
        return "I didn't hear anything. Could you please repeat that?"
    
    logger.info(f"Getting AI response for: '{prompt}'")
    
    try:
        # TODO: Uncomment and configure when using actual AI service
        # 
        # # Option 1: OpenAI API
        # response = openai.ChatCompletion.create(
        #     model=AI_MODEL_NAME,
        #     messages=[
        #         {"role": "system", "content": "You are Wall-E, a friendly companion robot. "
        #                                      "Keep responses short and friendly."},
        #         {"role": "user", "content": prompt}
        #     ],
        #     max_tokens=100,
        #     temperature=0.7
        # )
        # return response.choices[0].message.content.strip()
        # 
        # # Option 2: Local Hugging Face model
        # if _ai_model:
        #     response = _ai_model(prompt, max_length=100, num_return_sequences=1)
        #     return response[0]['generated_text'].strip()
        
        # TEMPORARY: Simulation mode with predefined responses
        responses = {
            "hello": "Hello! I'm Wall-E, your companion robot. How can I help you today?",
            "how are you": "I'm doing great! My systems are running smoothly and I'm ready for adventure!",
            "follow me": "Of course! I'll follow you. Just start walking and I'll be right behind you.",
            "stop": "Stopping now! Is everything okay?",
            "what do you see": "I can see you clearly! I'm also scanning for obstacles to keep us safe.",
            "who are you": "I'm Wall-E, an AI companion robot built by an amazing team of students!",
            "thank you": "You're very welcome! I'm happy to help.",
            "goodbye": "Goodbye! It was great spending time with you. See you soon!"
        }
        
        # Find best matching response
        prompt_lower = prompt.lower()
        for key, response in responses.items():
            if key in prompt_lower:
                return response
        
        # Default response
        return "That's interesting! I'm still learning, but I'm here to be your companion. What would you like to do?"
        
    except Exception as e:
        logger.error(f"Error getting AI response: {e}")
        return "I'm having trouble thinking right now. Could you try asking me again?"

def cleanup() -> None:
    """
    Stops any ongoing speech and releases audio resources.
    """
    global _audio_initialized, _tts_thread
    
    if not _audio_initialized:
        return
    
    logger.info("Cleaning up audio system...")
    
    try:
        # Stop any ongoing speech
        if not _speech_queue.empty():
            # Clear the queue
            while not _speech_queue.empty():
                try:
                    _speech_queue.get_nowait()
                    _speech_queue.task_done()
                except queue.Empty:
                    break
        
        # Wait for TTS thread to finish
        if _tts_thread and _tts_thread.is_alive():
            _tts_thread.join(timeout=2.0)
        
        # TODO: Uncomment when using actual TTS engine
        # if _tts_engine:
        #     _tts_engine.stop()
        
        _audio_initialized = False
        logger.info("Audio system cleanup complete")
        
    except Exception as e:
        logger.error(f"Error during audio cleanup: {e}")

def set_volume(volume: float) -> None:
    """
    Set the TTS volume level.
    
    Args:
        volume: Volume level (0.0 to 1.0)
    """
    if not (0.0 <= volume <= 1.0):
        raise ValueError("Volume must be between 0.0 and 1.0")
    
    # TODO: Uncomment when using actual TTS engine
    # if _tts_engine:
    #     _tts_engine.setProperty('volume', volume)
    
    logger.info(f"Volume set to {volume:.1f}")

def set_speech_rate(rate: int) -> None:
    """
    Set the TTS speaking rate.
    
    Args:
        rate: Words per minute (typically 100-300)
    """
    if not (50 <= rate <= 400):
        raise ValueError("Speech rate must be between 50 and 400 WPM")
    
    # TODO: Uncomment when using actual TTS engine
    # if _tts_engine:
    #     _tts_engine.setProperty('rate', rate)
    
    logger.info(f"Speech rate set to {rate} WPM")

def test_audio() -> None:
    """Test function to verify audio system is working."""
    if not _audio_initialized:
        logger.error("Cannot test audio - not initialized")
        return
    
    logger.info("Testing audio system...")
    
    # Test TTS
    speak("Hello! This is a test of the text to speech system.")
    time.sleep(3)
    
    # Test AI responses
    test_prompts = ["hello", "how are you", "what do you see"]
    for prompt in test_prompts:
        response = get_intelligent_response(prompt)
        logger.info(f"AI Test - Prompt: '{prompt}' -> Response: '{response}'")
        speak(response)
        time.sleep(2)
    
    # Test speech recognition
    logger.info("Testing speech recognition (simulation)...")
    for i in range(3):
        command = listen_and_transcribe()
        if command:
            logger.info(f"Recognized command: '{command}'")
            response = get_intelligent_response(command)
            speak(response)
        time.sleep(1)
    
    logger.info("Audio test complete")

if __name__ == "__main__":
    # Test the module independently
    logging.basicConfig(level=logging.INFO)
    
    try:
        setup()
        test_audio()
    except KeyboardInterrupt:
        logger.info("Test interrupted")
    finally:
        cleanup()
